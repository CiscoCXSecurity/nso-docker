* NSO in Docker for development and production
  This repository contains all you need to build Docker images out of Cisco NSO. It produces two Docker images;
  - a production image
    - stripped of documentation and similar to make it small
    - use this as a base image in the Dockerfile for your production container image
      - add your own packages on top
  - a development image
    - contains Java compiler and other useful tools
    - can be used directly to compile packages and similar

  The development image can be used immediately, for example as the image for a CI docker container runner to use for running CI jobs that involve compilation of NSO packages and similar. The production image is intended to be used as a base image on which you add your own packages, like NEDs and your service packages, to produce a final image for your environment.

* How and why?
  There are many reasons for why Docker and containers in general might be good for you. The main drivers for using Docker with NSO lies around packaging, ensuring consistency in testing and production as well as making it simple and convenient to create test environments.

  - build a docker image out of a specific version of NSO and your packages
    - distributed as one unit!
    - you test the combination of NSO version X and version Y of your packages
      - think of it as a "version set"
    - the same version set that is tested in CI is deployed in production
      - guarantees you tested same thing you deploy
    - conversely, using other distribution methods, you increase the risk of testing one thing and ending up deploying something else - i.e. you didn't really test what you use in production
  - having NSO in a container makes it easy to start
    - simple to test
    - simple to run in CI
    - simple to use for development
  - you do NOT need Kubernetes, Docker swarm or other fancy orchestration
    - run Docker engine on a single machine

  It's also worth noting that using Docker does not mean you have to replace all of your current infrastructure. If you are currently using OpenStack or some system that primarily deals with virtual machines you don't have to rip this out. On the particular VM that runs NSO you can simply install Docker and have a single machine Docker environment that runs NSO. You are using Docker for the packaging features!

  Yet another alternative is to use Docker for development and CI and when it's time to deploy to production you use something entirely different. Docker images are glorified tar files so it is possible to extract the relevant files from them and deploy by other means.

* Usage
  The ideal scenario would be to ship prebuilt Docker images containing NSO but as legal requirements prevent that, this is the second best option. This repository contains recipes that you can use to produce Docker images yourself. Just add +water+ Cisco NSO ;)

** Building
*** Manually building Docker images on your local machine
   - Clone this repository to your local machine
     - ~git clone git@gitlab.com/nso-developer/nso-docker.git~
   - Download Cisco NSO
     - go to https://developer.cisco.com/docs/nso/ and click the "Download NSO for evaluation (Linux)" in the side bar
   - Place the downloaded .bin file in ~nso-install-files/~ in this repository
   - run ~make~ in repository root directory
     - *NOTE*: running docker commands, which are invoked by ~make~, typically require root privileges or membership in the ~docker~ group
   - verify your new images are built with ~docker images~ which should look something like:
     - *NOTE*: docker images are only tagged with the correct NSO version when run in the git master branch

   #+BEGIN_SRC shell
     kll@ThinkLite:~/nso-docker# docker images
     REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
     cisco-nso-base      5.2                 c451b581d328        19 hours ago        435MB
     cisco-nso-base      4.7.5               3096fe46bee9        19 hours ago        433MB
     cisco-nso-dev       5.2                 a986314ec390        22 hours ago        435MB
     <none>              <none>              7e680e680923        22 hours ago        410MB
     cisco-nso-dev       4.7.5               0565a58c3977        22 hours ago        433MB
     <none>              <none>              d968a53420ab        22 hours ago        421MB
     bitnami/minideb     buster              25dfa3b9a987        23 hours ago        67.5MB
     docker              stable              b40e5afd78f5        2 weeks ago         216MB
     kll@ThinkLite:~/nso-docker#
   #+END_SRC

*** Automatically building Docker images using Gitlab CI
   - Clone this repository to your local machine
     - ~git clone git@gitlab.com/nso-developer/nso-docker.git~
   - Download Cisco NSO
     - go to https://developer.cisco.com/docs/nso/ and click the "Download NSO for evaluation (Linux)" in the side bar
   - Place the downloaded .bin file in ~nso-install-files/~ in this repository
   - commit file(s) in ~nso-install-files/~ using git LFS and push
     - ~git add nso-install-files/*~
     - ~git commit nso-install-files -m "Add NSO install files"~
       - it is a good practice to add the files one by one and write the version you added in the commit message, like =Add NSO install file for v4.7.5=
     - ~git push -u origin master~
     - CI will now build the docker images for you
       - naturally provided you first setup CI
   - verify your new images are built by going to the container repository in Gitlab viewing the list of container images

*** Alternative for providing NSO install files into CI runner
    The above method involves committing the NSO install files to this git repository (your clone of it). This means the repository must be private so that you don't leak the NSO install files nor the produced Docker images. There are a number of reasons for why this setup might not be ideal;
    - you have an open source public repo and wish to run CI publicly
    - LFS doesn't work with your choice of code hosting
    - NSO install files are too big or you just don't like LFS

    There is an alternative. The path in which the build process looks for the NSO install file(s) is specified by ~NSO_INSTALL_FILES_DIR~. The default value is ~nso-install-files/~, i.e. a directory relative to the root of the repository. The standard way of delivering the NSO install files, as outlined in the process above, is to place the NSO files in that directory. The alternative is to change the ~NSO_INSTALL_FILES_DIR~ variable. Note how you can set this environment variable through the GitLab CI settings page under variables. You do *not* need to commit anything. In case you are running Gitlab CI with the ~docker~ runner, add the path to the list of ~volumes~, for example:

    #+BEGIN_SRC text
      [[runners]]
        name = "my-runner"
        url = "https://gitlab.com/"
        token = "s3cr3t"
        executor = "docker"
        [runners.docker]
          tls_verify = false
          image = "debian:buster"
          privileged = false
          disable_entrypoint_overwrite = false
          oom_kill_disable = false
          disable_cache = false
          volumes = ["/cache", "/var/run/docker.sock:/var/run/docker.sock", "/data/nso-install-files:/nso-install-files"]
          shm_size = 0
    #+END_SRC

    The path ~/data/nso-install-files~ on the host machine becomes available as ~/nso-install-files/~ in the CI build docker containers and by specifying that path (~/nso-install-files~) using the CI variable settings, the job will now pick up the NSO images from there. This is how the public repo at https://gitlab.com/nso-developer/nso-docker works. It allows us to host all code in public, run CI tests in public yet not reveal the NSO install file as required by its EULA.

** Running
*** Run standalone for testing
    - if you built a production image, i.e. using base image from this repo and adding in your own packages
    - run a standalone container
    - no persistent volume - since we are doing testing we don't need to survive a restart
    - use docker networking - connect to other things running in docker, like netsim etc

    #+BEGIN_SRC shell
      docker run -itd --name nso-dev1 my-prod-image:12345
    #+END_SRC

*** Run for development
    - mount the source code directory into the container
    - makes it possible to use compiler etc in the container
    - avoid installing compilers and other tools directly on your computer

    #+BEGIN_SRC shell
      docker run -itd --name nso-dev1 -v $(pwd):/src cisco-nso-dev:5.2
    #+END_SRC

*** Run for production
    - with a production image, i.e. using the base image from this repo and adding in your own packages
    - use shared volume to persist data across restarts
      - CDB (NSO database)
      - SSH & SSL keys
      - NETCONF notification replay
      - rollbacks
      - backups
      - optionally NSO logs
        - if remote (syslog) logging is used there is little need to persist logs
        - if local logging, then persisting logs is a good idea
    - possibly use --net=host to share IP address with host machine
      - makes it easier to handle connectivity

    This uses the ~--net=host~ option to let the container live in the hosts networking namespace. This means that it binds to the IP address of the (virtual) machine it is running on. NSO is configured to expose the CLI over SSH on port 22. If you have SSH running on the VM, there will be a collision when using ~--net=host~. To avoid port collision you can reconfigure NSO to listen on a different port by setting the =SSH_PORT= environment variable. Also note that we use a shared volume for logs. ~/log~ inside the container contains the logs and you can access them outside the container in ~/data/nso-logs~.
    #+BEGIN_SRC shell
      docker run -itd --name nso -v /data/nso:/nso -v /data/nso-logs:/log --net=host -e SSH_PORT=2024 my-prod-image:12345
    #+END_SRC

** Configuration options
   The ncs.conf configuration file for NSO is written at run time of the container. It is generated (modified to be precise) at startup of the container. It is possible to influence the configuration through a number of variables. These can be fed into the container through environment variables.

   | Environment variable | Type    | Default | Description                                   |
   |----------------------+---------+---------+-----------------------------------------------|
   | PAM                  | boolean | false   | Enable PAM instead of local auth in NSO (AAA) |
   | HTTP_ENABLE          | boolean | false   | Enable HTTP web UI                            |
   | HTTPS_ENABLE         | boolean | false   | Enable HTTPS (TLS) web UI                     |
   | SSH_PORT             | uint16  | 22      | Set port for SSH to listen on                 |

* Docker image tags
  The Docker images produced by this repo per default carry a unique tag based on the CI_JOB_ID variable set by Gitlab CI, for example ~registry.gitlab.com/nso-developer/nso-docker/cisco-nso-dev:31337~ where =31337= is the value from =CI_JOB_ID=.

  In addition, if the job is built on the =master= branch, it will also receive a tag based on the NSO version it contains, for example if the previously mentioned image is based on NSO 5.2.1, if it was built from the =master= branch it would also get the tag ~registry.gitlab.com/nso-developer/nso-docker/cisco-nso-dev:5.2.1~. This makes it possible for other repositories to use the ~5.2.1~ tag to always refer to the latest build of ~5.2.1~.

  It is recommended to use a nightly job to produce new images every night that include the latest security patches and similar to the base images. Do note however that this also means that updates to packages will happen and that could have negative consequences if they are not fully backwards compatible. These images are based on Debian stable but for example, pylint has been known to include additional lints in newer version and so new version of the image could include change like this which lead to unintended results.

  For a truly deterministic environment, downstream repositories that rely on these Docker images should be based on the unique tag and consequently be updated with the same cadence as new images are built.

* Exposed ports
 | Protocol | Port | Use               | Config var |
 |----------+------+-------------------+------------|
 | TCP      |   22 | SSH               | SSH_PORT   |
 | TCP      |   80 | HTTP              |            |
 | TCP      |  443 | HTTPS             |            |
 | TCP      |  830 | NETCONF           |            |
 | TCP      | 4334 | NETCONF call-home |            |

 It is possible to reconfigure the port that SSH uses by setting the SSH_PORT variable to the wanted value.

* Admin user
  An admin user can be created on startup by the run script in the container. There are three environment variables that control the addition of an admin user;
  - ~ADMIN_USERNAME~: username of the admin user to add, default is ~admin~
  - ~ADMIN_PASSWORD~: password of the admin user to add
  - ~ADMIN_SSHKEY~: private SSH key of the admin user to add

  As ~ADMIN_USERNAME~ already has a default value, only ~ADMIN_PASSWORD~ or ~ADMIN_SSHKEY~ need to be set in order to create an admin user. For example:
  #+BEGIN_SRC shell
    docker run -itd --name nso -e ADMIN_PASSWORD=foobar my-prod-image:12345
  #+END_SRC

  This can be very useful when starting up a container in CI for testing or when doing development. It is typically not required in a production environment where there is a permanent CDB that already contains the required user accounts.

  Also note how this only adds a user. If you are using a permanent volume for CDB etc and start the NSO container multiple times with different ~ADMIN_PASSWORD~ then the last run will effectively overwrite the older password. However, if you change ~ADMIN_USERNAME~ between invocations then you will create multiple users! An admin user account created during the last run of NSO will *not* be removed just because ~ADMIN_USERNAME~ is set to a different value.

* Python VM version
  These docker images default to using python3.

  In NSO v5.3 and later, the python VM to use is probed by first looking for ~python3~, if not found ~python2~ will be tried and finally it will fall back to running ~python~. In earlier versions of NSO, ~python~ is executed, which on most systems means python2. As python2 is soon end of life, these docker images default to using ~python3~.

* Backup
  *NOTE*: SSH keys and SSL certificates are not included in backups produced by ~ncs-backup~.
  Backup and restore largely behaves as it normally does with ~ncs-backup~ as run outside of Docker, with some exceptions.

  Normally, the ncs-backup script includes the NCS_CONFIG_DIR (defaults to /etc/ncs). SSH keys and SSL certificates are normally placed in /etc/ncs/ssh and /etc/ncs/ssl respectively. This means that the SSH keys and SSL certificates are part of the produced backup file. This is NOT the case for when NSO is run in a container as SSH keys and SSL certificates are not in the default configuration path.

** Taking a backup
   To take a backup, simply run ~ncs-backup~. The backup file will be written to ~/nso/run/backups~.

** Restoring from a backup
   To restore a backup, NSO must not be running. As you likely only have access to the ~ncs-backup~ tool and the volume containing CDB and other run time state from inside of the NSO container, this poses a slight challenge. Additionally, shutting down NSO will terminate the NSO container.

   What you need to do is shut down the NSO container and start a new one with the same persistent shared volume mounted but with a different command. Instead of running the ~/run-ncs.sh~ which is the normal command of the NSO container, you should run something that keeps the container alive but doesn't start NSO, for example ~read DUMMY~ (it's a bash builtin command so still have to run bash). A full docker command could look like:

   #+BEGIN_SRC shell
     docker run -itd --name nso -v /data/nso:/nso -v /data/nso-logs:/log --net=host my-prod-image:12345 bash -lc 'read DUMMY'
   #+END_SRC

   You now have the NSO container running but without NSO itself. Get a shell in the container with

   #+BEGIN_SRC shell
     docker exec -it nso bash -l
   #+END_SRC

   Then run the ncs-backup restore command, for example:

   #+BEGIN_SRC shell
     ncs-backup restore /nso/run/backups/ncs-4.7.5@2019-10-07T14:41:02.backup.gz
   #+END_SRC

   Or if you want to automate the whole process slightly you could do it all using docker exec and non-interactively:

   #+BEGIN_SRC shell
     docker exec -it nso bash -lc 'ncs-backup restore /nso/run/backups/ncs-4.7.5@2019-10-07T14:41:02.backup.gz --non-interactively'
   #+END_SRC

   Restoring a NSO backup should move the current run directory (~/nso/run~ to ~/nso/run.old~) and restore the run directory from the backup to the main run directory (~/nso/run~). After this is done, shut down your temporary container and start the normal NSO container again as usual.

* SSH host key
  NSO looks for the SSH host key in the directory =/nso/ssh=. The filename differs based on the configured host key algorithm. NSO in Docker will use the RSA algorithm for host keys.

  If no SSH host key exists, one will be generated. As it is stored in =/nso= which is typically a persistent shared volume in production setups, it will remain the same across restarts or upgrades of NSO.

  NSO version 5.3 and newer supports ed25519 and will in fact default to using ed25519 as server host key on new installations but this behavior is suppressed for NSO in Docker and instead RSA is used as it is supported by all currently existing versions of NSO.

* HTTPS TLS certificate
  NSO expects to find a TLS certificate and key at =/nso/ssl/cert/host.cert= and =/nso/ssl/cert/host.key= respectively. Since the =/nso= path is usually on persistent shared volume for production setups, the certificate remains the same across restarts or upgrades.

  When no certificate is present, one will be generated. It is a self-signed certificate valid for 30 days making it possible to use both in development and staging environments. It is *not* meant for production. You *should* replace it with a proper signed certificate for production and it is encouraged to do so even for test and staging environments. Simply generate one and place at the provided path, for example using the following, which is the command used to generate the temporary self-signed certificate:
  #+BEGIN_SRC shell
    openssl req -new -newkey rsa:4096 -x509 -sha256 -days 30 -nodes \
            -out /nso/ssl/cert/host.cert -keyout /nso/ssl/cert/host.key \
            -subj "/C=SE/ST=NA/L=/O=NSO/OU=WebUI/CN=Mr. Self-Signed"
  #+END_SRC

* NSO upgrades, downgrades, YANG model changes and package modifications
  As the produced Docker image contains both NSO itself and a given version of all included packages, any changes to said components will result in a new Docker image. Deploying any change, however small, means building and deploying a new Docker image. Upgrading and downgrading of NSO itself, with the packages kept static, is also based on deploying another Docker image.

** (Destructive) YANG model changes
   The database in NSO, called CDB, is using YANG models as the schema for the database. It is only possible to store data in CDB according to the YANG models that define the schema.

   If the YANG models are changed, in particular if nodes are removed or renamed (rename is basically a removal of one leaf and an addition of another), any data in CDB for those leaves will be removed. NSO normally warns about this when you attempt to load the new packages, for example ~request packages reload~ will refuse to reload the packages if nodes in the YANG model have disappeared. You would have to add the ~force~ argument, e.g. ~request packages reload force~.

   NSO in Docker will automatically reload packages on startup, using the ~--with-packages-reload-force~ argument to ~ncs~ on startup. This means that destructive model changes will be accepted without warning. It is expected that NSO in Docker is developed in an environment where there are other safe guards, such as CI testing, to catch accidental destructive model changes.

** NSO version 4 to 5 upgrade
   The major new feature in NSO version 5 is what's known as Common Data Models or CDM, which is based on the YANG schema-mount standard (RFC8528). With it, there are changes to the CDB database files on disk. The migration from a CDB written by NSO version 4 to NSO version 5 happens automatically but first the old CDB written by NSO version 4 must be compacted, which is a manual step. However, with NSO in Docker, the startup script takes care of this for you by automatically determining at startup if NSO version 5 is being started on a CDB written by NSO version 4. If this is the case, the CDB on disk is compacted.

   NSO 5 requires that packages, in particular NEDs, be compiled for CDM. Thus, upgrading to NSO 5 typically also involves upgrading one or more NEDs. In the process of changing NEDs and upgrading NSO there is the risk of inadvertently making model changes that lead to data loss, in which case the upgrade process needs to be reattempted. The overall upgrade process is something along the lines of:

   - take backup of CDB (in NSO 4 format)
   - compact CDB
   - take backup of CDB (in NSO 5 format)
   - start NSO 5
     - verify data integrity
     - if model / data inconsistencies have lead to data loss
       - restore from backup that contains NSO 5 compacted CDB
       - rectify packages
       - start NSO 5 with new packages
       - repeat until done

   Multiple attempts might be necessary to get everything to load and upgrade correctly. CDB compaction can take some time (depending on the size of CDB). By restoring from a backup of a compacted CDB, we avoid having to compact CDB for every retry.

   In a production setting with a structured approach to development and operations, the recommendation would be to take a backup of CDB from production and move to a development machine where the above steps can be executed. Preferably also incorporating not just the NED / package changes into CI but also including testing of the CDB upgrade. The upgrade is thus tested in development & CI before being attempted on the production deployment machines. While we might use a compacted CDB to speed up the development and testing of the upgrade, as outlined above, the actual upgrade of the production system will only happen once inside of an NSO container in an unsupervised fashion, which is why startup script of NSO in Docker will automatically determine the CDB version + NSO version and, if deemed necessary, perform CDB compaction.

* Modifying the NSO configuration file ncs.conf
  The ~ncs.conf~ used in the docker images produced by this repository is not checked into git but rather originates from the NSO install itself. This means that if we build a Docker image based on NSO 5.2 we will get the default ~ncs.conf~ that comes with ~5.2~. Any updates to the ~ncs.conf~ shipped with NSO will find its way into the Docker image. Since modifications are necessary, partly for NSO to fit into a Docker environment but also to apply instance specific configuration, like the administrator password, the ~ncs.conf~ configuration file is modified on startup. This is achieved by a startup script executed before NSO is started.

  The standard Docker run script (~run-nso.sh~) looks for files that ends with ~.sh~ in ~/etc/ncs/pre-ncs-start.d/~ and ~/etc/ncs/post-ncs-start.d/~ and will run any scripts found before or after starting NSO. This facility is used to modify the ~ncs.conf~ configuration file before NSO is started. ~/etc/ncs/pre-ncs-start.d/50-mangle-config.sh~ performs the necessary modifications. Since ~ncs.conf~ is a structured XML document, it primarily uses ~xmlstarlet~ to perform modification operations on the configuration file.

  You can further modify the ~ncs.conf~ configuration file by adding your own startup script in ~/etc/ncs.pre-ncs-start.d/~. Since the configuration file is an XML document, modification is best done through an XML aware tool. The previously mentioned standard ~mangle-config.sh~ script modifies the ~ncs.conf~ configuration file using ~xmlstarlet~  which understands XML and offers XML aware editing capabilities.

* Extending the Docker image
  There are multiple approaches to extending the functionality of the NSO docker image.

  The standard Docker run script (~run-nso.sh~) looks for files that ends with ~.sh~ in ~/etc/ncs/pre-ncs-start.d/~ and ~/etc/ncs/post-ncs-start.d/~ and will run any scripts found before or after starting NSO. ~ncs --wait-started~ is used to wait for NSO to start. If you want to modify the configuration file, produce some XML files to be read into CDB on startup or similar, you can write a script for that and place it in the relevant startup directory (typically before NSO is started).

  In other situations you want to run scripts that load or modify some configuration in NSO (CDB) somehow, which might be better suited to be placed in ~/etc/ncs/post-ncs-start.d~ (though don't mistake these capabilities for what CDB upgrade logic and similar offers). For example, it is possible to start another process in the same container and if that process is dependent upon NSO having started, placing the script in ~/etc/ncs/post-ncs-start-d/~ is a convenient approach as those scripts are only started after NSO have started up (as determined by ~ncs --wait-started~).

* Healthcheck
  The production-base image comes with a basic Docker healthcheck. It is using ncs_cmd to get the phase that NCS is currently in. Only the result status, i.e. if ncs_cmd was able to communicate with the ~ncs~ process or not, is actually observed. This tells us whether the ~ncs~ process is responding to IPC requests.

  As far as monitoring NSO goes, this is a very basic check. Just a tad above the basic process check, i.e. that the ~ncs~ process is actually alive, which is the most basic premise of production-base image.

  More advanced and deeper looking healthchecks could be conceived, for example by observing locks and measuring the time a certain lock has been held, but it is difficult to find a completely generic set of conditions for flagging NSO as healthy or unhealthy based on that. For example, if a transaction lock has been held for 5 hours, is that healthy or not? In most situations, that would be an abnormally long transaction, but does it constitute an unhealthy state? In certain operational environments it could be normal with that long transactions (for example a batch import of some data). Marking the container as unhealthy and potentially restarting it as a consequence would only make things worse.

  We really want to measure some form of progress, even if that progress is just internal. A five hours transaction is fine as long as we are continuously making progress. However, there are currently no such indicators available and so the healthcheck observes the rather basic operation of the IPC listener.

* Make targets
  There are multiple make targets for building an NSO docker image.

** Based on NSO version
   Assuming the NSO install file has been placed in the ~NSO_INSTALL_FILES_DIR~ (per default ~nso-install-files/~), you can run:

   #+BEGIN_SRC shell
     make NSO_VERSION=5.2.1 build-version
   #+END_SRC

   To produce a docker image based on NSO 5.2.1. It requires that the corresponding installer file is present, i.e. ~nso-install-files/nso-5.2.1.linux.x86_64.installer.bin~.

** Based on complete path to NSO installer file
   You can use the ~build~ target to build a Docker image out of an NSO installer. It requires that you specify the complete path to the NSO
   installer file, for example:

   #+BEGIN_SRC shell
     make FILE=/home/foo/nso-docker/nso-install-files/nso-5.2.1.linux.x86_64.installer.bin build
   #+END_SRC

** For all NSO installer files in NSO_INSTALL_FILES_DIR
   To build docker images for all the NSO installer files present in the NSO installer directory, (specified by ~NSO_INSTALL_FILES_DIR~), you can run:

   #+BEGIN_SRC shell
     make build-all
   #+END_SRC

   There are targets to run tests that correspond with the above;
   - test-version
   - test
   - test-all
   They require the same variables to be set as their corresponding build target described above.

* Dependencies
  To build these images, you need:
  - Docker
  - Make

  If you want to run the test suite you also need:
  - sshpass

* GitLab CI runner
  *NOTE*: Using a Gitlab CI runner as described in this section has different security implications than what is normally associated with using containers for CI. See the Security sub-heading.

  In order to build the CI pipeline as defined for this repository you need GitLab and a GitLab CI runner. It is possible to use the free and public gitlab.com in order to host the code but you have to provide your own Gitlab CI runner. While you have access to CI runners simply by using gitlab.com to host your code, their capabilities don't match what is needed in order to build this project. Fortunately, Gitlab as a product makes it very simple to connect your own CI runner to any Gitlab instance, including the public gitlab.com one.

  1. Get a VM or a physical machine to run your CI runner.
  2. Install Debian on said machine.
  3. Follow the guide on https://docs.gitlab.com/runner/install/linux-repository.html to install the Gitlab CI runner on your machine
  4. Follow the guide at https://docs.gitlab.com/runner/register/ on how to register your runner with Gitlab
  5. Expose the docker control socket in the gitlab runner configuration

  Here's a configuration file for gitlab ci runner. Note the ~volumes~ setting which includes ~/var/run/docker.sock~ - this exposes the Docker control socket to the containers run by the CI runner which enables the containers to start /sibling/ containers.
  #+BEGIN_SRC text
    [[runners]]
      name = "my-runner"
      url = "https://gitlab.com/"
      token = "s3cr3t"
      executor = "docker"
      [runners.docker]
        tls_verify = false
        image = "debian:buster"
        privileged = false
        disable_entrypoint_overwrite = false
        oom_kill_disable = false
        disable_cache = false
        volumes = ["/cache", "/var/run/docker.sock:/var/run/docker.sock"]
        shm_size = 0
  #+END_SRC
  You naturally need to use your token and not literally ~s3cr3t~. The token is written when you do the runner registration per the guide referenced above.

** Security
   Note that exposing the Docker control socket has security implications. Containers as run by the CI runner normally provide isolation such that CI jobs are contained within the container and are unable to access anything outside of the container. By exposing the docker control socket, the CI jobs can start new containers, including starting a privileged one, which means it has root access on the host machine and enables escaping the container entirely. Do not grant access to your project or CI runner to anyone you do not trust. For example, someone that is able to create a branch on your repository can write a Gitlab CI configuration file that instructs the CI runner to run a privileged container and then gain access to the CI runner machine itself.

* GitLab CI configuration files for inclusion
  New NSO versions are released periodically and over time the list of NSO versions grows fairly long. For someone writing a NSO package, keeping the list of NSO versions to build and test for in CI up to date can be a time consuming task, in particular if there are many packages to be maintained. GitLab CI allows for inclusion of configuration files such that the project CI configuration can include another file that is external to the repo. By using this feature we can keep a central list of the NSO versions to test with.

  ~version-includes/versions.json~ is the root definition of the currently supported versions. ~version-includes/gen.py~ is a Python script that uses ~versions.json~ as input and produces a number of YAML files that can be included in other repositories.

  For example, we have ~build-all.yaml~, which uses the prototypical CI job definition called =build= and defines jobs for all currently supported versions of NSO.

  ~build-all4.yaml~ is similar but only includes NSO 4.x versions, whereas ~build-all5.yaml~ does the same for NSO 5.x. Since NSO 5 looks quite different with schema-mount, it could be reasonable for some packages to only target NSO 5.

  ~build-tot.yaml~ only includes the "tip" of each train, where a train is the combination of a major and minor version number. Patch releases are not considered for tip-of-train as they are not supposed to be used by the wide masses. For example, if we have 4.7, 4.7.1, 4.7.2 and 4.7.2.1 as well as 5.2.1, the tip-of-train would include 4.7.2 and 5.2.1.

  To include a file, use the ~include~ directory, for example:
  #+BEGIN_SRC yaml
    include:
      - project: 'nso-developer/nso-docker'
        ref: master
        file: '/version-includes/build-tot5.yaml'
  #+END_SRC
  This will work for any repository hosted on the same GitLab instance as the =nso-developer/nso-docker= repo. Once you clone the =nso-docker= repository to your own environment, as you are encouraged to do, you are likely to place it in another namespace (not =nso-developer=) and so you must update the include statements for the dependent repositories accordingly.

* FAQ / Questions and answers
** Q: Why are these images not based on alpine or some other minimal container friendly image
   *A*: The larger the final container image is, the less impact the base image size typically has. Picking a 5MB or 50MB base image is not crucial when the final image is an order of magnitude larger.

   Debian was chosen as it is a well working proven distribution with a long track record. It is supported by a considerably sized community.

   minideb, which is a minimal build of a debian base image, was not only considered but actually used in early phases of this repository. It does provide a smaller image. Measured at the time of the switch from minideb to stock debian, the difference was about 10%. minideb weighed in at 471MB while debian:buster came in at 525MB. The proven track record of Debian ultimately made it the winner.
